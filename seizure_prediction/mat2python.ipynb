{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "33ecf6a5-3b67-69fc-654c-03c5b9d3764b"
   },
   "source": [
    "This is the direct translation of the Matlab getting started code shared by the organizers. \n",
    "This feature extractor was used as part of a winning solution in a past competition.\n",
    "EDIT: I have fixed the mistakes in the original Matlab code in this new version.\n",
    "\n",
    "NOTE: I just tried to translate it from the Matlab version as close as possible. \n",
    "            Use at your own risk. Correctness is not guaranteed and there might be bugs in \n",
    "            this translation and/or the original Matalb version. So, debug very well before \n",
    "            incorporating it to your pipeline.\n",
    "\n",
    "DISCLAIMER: I still haven't tried it with my training pipeline so I am not sure for correctness yet.\n",
    "                          \n",
    "GIVE BACK: Please, consider to fork and contribute back your feature additions and/or corrections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "f9a60963-6d3f-5f79-ed53-aaadd421e2bc"
   },
   "outputs": [],
   "source": [
    "# translation of the Matlab feature extractor\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import *\n",
    "from scipy.io import loadmat\n",
    "from scipy.stats import skew, kurtosis\n",
    "#import pyeeg \n",
    "# pyeeg is the one that has very good fractal dimensions \n",
    "# computation but not installed here\n",
    "\n",
    "def mat_to_data(path):\n",
    "    mat = loadmat(path)\n",
    "    names = mat['dataStruct'].dtype.names\n",
    "    ndata = {n: mat['dataStruct'][n][0, 0] for n in names}\n",
    "    return ndata\n",
    "\n",
    "def corr(data,type_corr):\n",
    "    C = np.array(data.corr(type_corr))\n",
    "    C[np.isnan(C)] = 0\n",
    "    C[np.isinf(C)] = 0\n",
    "    w,v = np.linalg.eig(C)\n",
    "    #print(w)\n",
    "    x = np.sort(w)\n",
    "    x = np.real(x)\n",
    "    return x\n",
    "\n",
    "def calculate_features(file_name):\n",
    "    f = mat_to_data(file_name)\n",
    "    fs = f['iEEGsamplingRate'][0,0]\n",
    "    eegData = f['data']\n",
    "    [nt, nc] = eegData.shape\n",
    "    print((nt, nc))\n",
    "    subsampLen = floor(fs * 60)\n",
    "    numSamps = int(floor(nt / subsampLen));      # Num of 1-min samples\n",
    "    sampIdx = range(0,(numSamps+1)*subsampLen,subsampLen)\n",
    "    #print(sampIdx)\n",
    "    feat = [] # Feature Vector\n",
    "    for i in range(1, numSamps+1):\n",
    "        print('processing file {} epoch {}'.format(file_name,i))\n",
    "        epoch = eegData[sampIdx[i-1]:sampIdx[i], :]\n",
    "\n",
    "        # compute Shannon's entropy, spectral edge and correlation matrix\n",
    "        # segments corresponding to frequency bands\n",
    "        lvl = np.array([0.1, 4, 8, 12, 30, 70, 180])  # Frequency levels in Hz\n",
    "        lseg = np.round(nt/fs*lvl).astype('int')\n",
    "        D = np.absolute(np.fft.fft(epoch, n=lseg[-1], axis=0))\n",
    "        D[0,:]=0                                # set the DC component to zero\n",
    "        D /= D.sum()                      # Normalize each channel               \n",
    "        \n",
    "        dspect = np.zeros((len(lvl)-1,nc))\n",
    "        for j in range(len(dspect)):\n",
    "            dspect[j,:] = 2*np.sum(D[lseg[j]:lseg[j+1],:], axis=0)\n",
    "\n",
    "        # Find the shannon's entropy\n",
    "        spentropy = -1*np.sum(np.multiply(dspect,np.log(dspect)), axis=0)\n",
    "\n",
    "        # Find the spectral edge frequency\n",
    "        sfreq = fs\n",
    "        tfreq = 40\n",
    "        ppow = 0.5\n",
    "\n",
    "        topfreq = int(round(nt/sfreq*tfreq))+1\n",
    "        A = np.cumsum(D[:topfreq,:])\n",
    "        B = A - (A.max()*ppow)\n",
    "        spedge = np.min(np.abs(B))\n",
    "        spedge = (spedge - 1)/(topfreq-1)*tfreq\n",
    "\n",
    "        # Calculate correlation matrix and its eigenvalues (b/w channels)\n",
    "        data = pd.DataFrame(data=epoch)\n",
    "        type_corr = 'pearson'\n",
    "        lxchannels = corr(data, type_corr)\n",
    "        \n",
    "        # Calculate correlation matrix and its eigenvalues (b/w freq)\n",
    "        data = pd.DataFrame(data=dspect)\n",
    "        lxfreqbands = corr(data, type_corr)\n",
    "        \n",
    "        # Spectral entropy for dyadic bands\n",
    "        # Find number of dyadic levels\n",
    "        ldat = int(floor(nt/2.0))\n",
    "        no_levels = int(floor(log(ldat,2.0)))\n",
    "        seg = floor(ldat/pow(2.0, no_levels-1))\n",
    "\n",
    "        # Find the power spectrum at each dyadic level\n",
    "        dspect = np.zeros((no_levels,nc))\n",
    "        for j in range(no_levels-1,-1,-1):\n",
    "            dspect[j,:] = 2*np.sum(D[int(floor(ldat/2.0))+1:ldat,:], axis=0)\n",
    "            ldat = int(floor(ldat/2.0))\n",
    "\n",
    "        # Find the Shannon's entropy\n",
    "        spentropyDyd = -1*np.sum(np.multiply(dspect,np.log(dspect)), axis=0)\n",
    "\n",
    "        # Find correlation between channels\n",
    "        data = pd.DataFrame(data=dspect)\n",
    "        lxchannelsDyd = corr(data, type_corr)\n",
    "        \n",
    "        # Fractal dimensions\n",
    "        no_channels = nc\n",
    "        #fd = np.zeros((2,no_channels))\n",
    "        #for j in range(no_channels):\n",
    "        #    fd[0,j] = pyeeg.pfd(epoch[:,j])\n",
    "        #    fd[1,j] = pyeeg.hfd(epoch[:,j],3)\n",
    "        #    fd[2,j] = pyeeg.hurst(epoch[:,j])\n",
    "\n",
    "        #[mobility[j], complexity[j]] = pyeeg.hjorth(epoch[:,j)\n",
    "        # Hjorth parameters\n",
    "        # Activity\n",
    "        activity = np.var(epoch, axis=0)\n",
    "        #print('Activity shape: {}'.format(activity.shape))\n",
    "        # Mobility\n",
    "        mobility = np.divide(\n",
    "                            np.std(np.diff(epoch, axis=0)), \n",
    "                            np.std(epoch, axis=0))\n",
    "        #print('Mobility shape: {}'.format(mobility.shape))\n",
    "        # Complexity\n",
    "        complexity = np.divide(np.divide(\n",
    "                                        # std of second derivative for each channel\n",
    "                                        np.std(np.diff(np.diff(epoch, axis=0), axis=0), axis=0),\n",
    "                                        # std of second derivative for each channel\n",
    "                                        np.std(np.diff(epoch, axis=0), axis=0))\n",
    "                               , mobility)\n",
    "        #print('Complexity shape: {}'.format(complexity.shape))\n",
    "        # Statistical properties\n",
    "        # Skewness\n",
    "        sk = skew(epoch)\n",
    "\n",
    "        # Kurtosis\n",
    "        kurt = kurtosis(epoch)\n",
    "\n",
    "        # compile all the features\n",
    "        feat = np.concatenate((feat,\n",
    "                               spentropy.ravel(),\n",
    "                               spedge.ravel(),\n",
    "                               lxchannels.ravel(),\n",
    "                               lxfreqbands.ravel(),\n",
    "                               spentropyDyd.ravel(),\n",
    "                               lxchannelsDyd.ravel(),\n",
    "                               #fd.ravel(),\n",
    "                               activity.ravel(),\n",
    "                               mobility.ravel(),\n",
    "                               complexity.ravel(),\n",
    "                               sk.ravel(),\n",
    "                               kurt.ravel()\n",
    "                                ))\n",
    "\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "57c4e54a-fa1d-0cac-f0e6-7249fa702ad4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240000, 16)\n",
      "processing file ../input/train_1/1_1_1.mat epoch 1\n",
      "processing file ../input/train_1/1_1_1.mat epoch 2\n",
      "processing file ../input/train_1/1_1_1.mat epoch 3\n",
      "processing file ../input/train_1/1_1_1.mat epoch 4\n",
      "processing file ../input/train_1/1_1_1.mat epoch 5\n",
      "processing file ../input/train_1/1_1_1.mat epoch 6\n",
      "processing file ../input/train_1/1_1_1.mat epoch 7\n",
      "processing file ../input/train_1/1_1_1.mat epoch 8\n",
      "processing file ../input/train_1/1_1_1.mat epoch 9\n",
      "processing file ../input/train_1/1_1_1.mat epoch 10\n",
      "[ 0.47285908  0.39043649  0.37995357 ...,  8.69945049  8.995224    1.88705349]\n",
      "(1610,)\n"
     ]
    }
   ],
   "source": [
    "feat = calculate_features('../input/train_1/1_1_1.mat')\n",
    "print(feat)\n",
    "print(feat.shape)"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 140,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
